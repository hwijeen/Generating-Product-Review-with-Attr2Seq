{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from data_loader import get_dataset_loader\n",
    "from model import Encoder, AttnDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():        \n",
    "    \n",
    "    # Data \n",
    "    #csv_file = 'data/complete_df.csv'\n",
    "    csv_file = 'data/toy_df.csv'\n",
    "    vocab_file = 'crawling/Reviews_csv/vocab.txt'\n",
    "    tag_vocab = 'crawling/tags_txt/tag_vocab.txt'\n",
    "    rating_dict = {'불만':0, '추천안함':0,\n",
    "                    '보통':1,\n",
    "                    '추천':2, '만족':2,\n",
    "                    '적극추천':3}\n",
    "    category = 'subcat'    # 'subcat' or 'category'\n",
    "        \n",
    "    def add_dataset_info(self, dataset):\n",
    "        \"\"\"data loading이후에 결정되는 것들\"\"\"\n",
    "        self.rating_size = len(dataset.rating2idx)\n",
    "        self.category_size = len(dataset.category2idx)\n",
    "        self.tag_size = len(dataset.tag2idx)\n",
    "        self.output_size = len(dataset.word2idx)\n",
    "        self.padding_idx = dataset.word2idx['PAD']  # 0\n",
    "        self.SOS_token = dataset.word2idx['SOS']    # 1\n",
    "        self.EOS_token = dataset.word2idx['EOS']    # 2\n",
    "    # Encoder\n",
    "    # pretrained = False \n",
    "    attribute_size = 64\n",
    "    \n",
    "    # Decoder\n",
    "    hidden_size = 512 \n",
    "    num_layers = 2\n",
    "    num_attr = 3 # for attention!\n",
    "    \n",
    "    # training\n",
    "    batch_size = 50\n",
    "    dropout = 0.2\n",
    "    num_steps = 100\n",
    "    print_every = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(encoder, decoder, dataloader, loss_fn, optimizer, config, verbose=False):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    \n",
    "    \n",
    "    def splitHidden(encoder_output):\n",
    "        h_0 = encoder_output.view(config.num_layers, config.batch_size,                               config.hidden_size)\n",
    "        c_0 = torch.zeros_like(h_0) \n",
    "        return (h_0, c_0)\n",
    "    \n",
    "    for t in tqdm_notebook(range(config.num_steps)):\n",
    "        optimizer.zero_grad()\n",
    "        data_iter = iter(dataloader)    # batching할 때 어떻게 할지 수정 필요\n",
    "        \n",
    "        rating_tensor, category_tensor, tag_tensor, target_tensor = next(data_iter)\n",
    "        target_length = target_tensor.size(-1)\n",
    "        \n",
    "        attrs, encoder_output = encoder(rating_tensor, category_tensor, tag_tensor)\n",
    "        decoder_hidden = splitHidden(encoder_output)        \n",
    "        decoder_input = config.SOS_token * torch.ones((config.batch_size,1)).long() \n",
    "        \n",
    "        decoder_outputs = []\n",
    "        for idx in range(target_length): \n",
    "            decoder_output, decoder_hidden, attention_weights = \\\n",
    "                                        decoder(decoder_input, decoder_hidden, attrs)            \n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.detach().view(config.batch_size, 1)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, 1).view(config.batch_size*target_length, -1)\n",
    "        target_tensor = target_tensor.view(-1)\n",
    "        loss = loss_fn(decoder_outputs, target_tensor) \n",
    "        num_actual_token = torch.sum(target_tensor != encoder.config.padding_idx).item()\n",
    "        loss /= num_actual_token\n",
    "        \n",
    "        if verbose==True and t % config.print_every == 0:\n",
    "            print(\"loss at %d step: %f\" % (t, loss))\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data & set config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "dataset, dataloader = get_dataset_loader(config.csv_file, config.vocab_file, config.tag_vocab, config.rating_dict,                         config.category, config.batch_size)\n",
    "config.add_dataset_info(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate model and start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c07aac91948c4dc9b730d4a3c114042b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at 0 step: 10.102799\n",
      "loss at 1 step: 9.550422\n",
      "loss at 2 step: 8.512295\n",
      "loss at 3 step: 9.510113\n",
      "loss at 4 step: 7.948709\n",
      "loss at 5 step: 7.725322\n",
      "loss at 6 step: 6.978649\n",
      "loss at 7 step: 6.665123\n",
      "loss at 8 step: 6.229571\n",
      "loss at 9 step: 5.961671\n",
      "loss at 10 step: 6.047873\n",
      "loss at 11 step: 5.925772\n",
      "loss at 12 step: 6.324553\n",
      "loss at 13 step: 5.960098\n",
      "loss at 14 step: 5.971672\n",
      "loss at 15 step: 5.657265\n",
      "loss at 16 step: 5.632519\n",
      "loss at 17 step: 5.652637\n",
      "loss at 18 step: 5.376629\n",
      "loss at 19 step: 5.681334\n",
      "loss at 20 step: 5.432980\n",
      "loss at 21 step: 5.555317\n",
      "loss at 22 step: 5.258498\n",
      "loss at 23 step: 5.551787\n",
      "loss at 24 step: 5.542890\n",
      "loss at 25 step: 5.481921\n",
      "loss at 26 step: 5.254322\n",
      "loss at 27 step: 5.465711\n",
      "loss at 28 step: 5.257216\n",
      "loss at 29 step: 5.189991\n",
      "loss at 30 step: 5.476954\n",
      "loss at 31 step: 5.233053\n",
      "loss at 32 step: 5.107705\n",
      "loss at 33 step: 5.202115\n",
      "loss at 34 step: 5.221690\n",
      "loss at 35 step: 4.952003\n",
      "loss at 36 step: 4.953732\n",
      "loss at 37 step: 5.004900\n",
      "loss at 38 step: 5.171020\n",
      "loss at 39 step: 5.018693\n",
      "loss at 40 step: 5.035676\n",
      "loss at 41 step: 4.857923\n",
      "loss at 42 step: 5.056531\n",
      "loss at 43 step: 4.933344\n",
      "loss at 44 step: 5.129915\n",
      "loss at 45 step: 4.890470\n",
      "loss at 46 step: 4.740996\n",
      "loss at 47 step: 4.822934\n",
      "loss at 48 step: 4.682372\n",
      "loss at 49 step: 4.747310\n",
      "loss at 50 step: 4.744843\n",
      "loss at 51 step: 4.529060\n",
      "loss at 52 step: 4.450970\n",
      "loss at 53 step: 4.793734\n",
      "loss at 54 step: 4.424463\n",
      "loss at 55 step: 4.745805\n",
      "loss at 56 step: 4.620400\n",
      "loss at 57 step: 4.657345\n",
      "loss at 58 step: 4.656928\n",
      "loss at 59 step: 4.685894\n",
      "loss at 60 step: 4.513214\n",
      "loss at 61 step: 4.628116\n",
      "loss at 62 step: 4.412683\n",
      "loss at 63 step: 4.314895\n",
      "loss at 64 step: 4.517206\n",
      "loss at 65 step: 4.632329\n",
      "loss at 66 step: 4.707397\n",
      "loss at 67 step: 4.551156\n",
      "loss at 68 step: 4.273914\n",
      "loss at 69 step: 4.410757\n",
      "loss at 70 step: 4.368590\n",
      "loss at 71 step: 4.441223\n",
      "loss at 72 step: 4.273822\n",
      "loss at 73 step: 4.154300\n",
      "loss at 74 step: 4.269173\n",
      "loss at 75 step: 4.044231\n",
      "loss at 76 step: 4.543880\n",
      "loss at 77 step: 4.520003\n",
      "loss at 78 step: 3.946939\n",
      "loss at 79 step: 5.227106\n",
      "loss at 80 step: 5.621332\n",
      "loss at 81 step: 4.239545\n",
      "loss at 82 step: 4.343515\n",
      "loss at 83 step: 4.261531\n",
      "loss at 84 step: 4.150748\n",
      "loss at 85 step: 4.252213\n",
      "loss at 86 step: 4.221259\n",
      "loss at 87 step: 4.149029\n",
      "loss at 88 step: 3.993999\n",
      "loss at 89 step: 4.099203\n",
      "loss at 90 step: 4.195433\n",
      "loss at 91 step: 4.164095\n",
      "loss at 92 step: 4.143094\n",
      "loss at 93 step: 4.128754\n",
      "loss at 94 step: 4.116876\n",
      "loss at 95 step: 3.997132\n",
      "loss at 96 step: 4.141912\n",
      "loss at 97 step: 4.100152\n",
      "loss at 98 step: 3.863431\n",
      "loss at 99 step: 3.825395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(config)\n",
    "decoder = AttnDecoder(config)\n",
    "\n",
    "params = list(encoder.parameters()) + list(decoder.parameters())\n",
    "loss_fn = nn.NLLLoss(size_average=False, ignore_index=config.padding_idx)\n",
    "#optimizer = optim.Adam(params, lr=0.001)\n",
    "#optimizer = optim.SGD(params, lr=1)\n",
    "optimizer = optim.RMSprop(params, lr=0.002, alpha=0.95)\n",
    "\n",
    "train(encoder, decoder, dataloader, loss_fn, optimizer, config, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hwijeen_3.6]",
   "language": "python",
   "name": "conda-env-hwijeen_3.6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
