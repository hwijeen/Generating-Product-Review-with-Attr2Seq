{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import torch\n",
    "from collections import Counter\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'PAD_WORD' : 'PAD', 'PAD_IDX' : 0, 'UNK_WORD' : 'UNK', 'UNK_IDX' : 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/products.pkl', 'rb') as data:\n",
    "    all_prod = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['추천',\n",
       " 'bags',\n",
       " 12016021001,\n",
       " ['여자',\n",
       "  '가방',\n",
       "  '쇼핑몰',\n",
       "  '여자',\n",
       "  '옷',\n",
       "  '쇼핑몰',\n",
       "  '추천',\n",
       "  '대여',\n",
       "  '쇼핑몰',\n",
       "  '대여',\n",
       "  '쇼핑몰',\n",
       "  '여자',\n",
       "  '지갑',\n",
       "  '추천',\n",
       "  '여자',\n",
       "  '동전지갑',\n",
       "  '귀여운',\n",
       "  '동전지갑',\n",
       "  '퍼',\n",
       "  '동전지갑',\n",
       "  '여자',\n",
       "  '겨울',\n",
       "  '코디',\n",
       "  '여자',\n",
       "  '지갑',\n",
       "  '쇼핑몰'],\n",
       " ['SOS',\n",
       "  ('귀여운', 'Adjective'),\n",
       "  ('동전지갑', 'Noun'),\n",
       "  ('♡', 'Foreign'),\n",
       "  ('복실복실', 'Adverb'),\n",
       "  ('귀여운', 'Adjective'),\n",
       "  ('털', 'Noun'),\n",
       "  ('동전지갑', 'Noun'),\n",
       "  ('입니', 'Adjective'),\n",
       "  ('다', 'Eomi'),\n",
       "  ('.', 'Punctuation'),\n",
       "  ('가방', 'Noun'),\n",
       "  ('키링', 'Noun'),\n",
       "  ('으로도', 'Josa'),\n",
       "  ('괜찮', 'Adjective'),\n",
       "  ('구요', 'Eomi'),\n",
       "  ('~', 'Punctuation'),\n",
       "  ('열쇠', 'Noun'),\n",
       "  ('동전', 'Noun'),\n",
       "  ('립스틱', 'Noun'),\n",
       "  ('.', 'Punctuation'),\n",
       "  ('등', 'Noun'),\n",
       "  ('작은', 'Adjective'),\n",
       "  ('물건', 'Noun'),\n",
       "  ('들', 'Suffix'),\n",
       "  ('.', 'Punctuation'),\n",
       "  ('넣고', 'Verb'),\n",
       "  ('다니', 'Verb'),\n",
       "  ('기', 'Noun'),\n",
       "  ('에도', 'Josa'),\n",
       "  ('안성맞춤', 'Noun'),\n",
       "  ('입니', 'Adjective'),\n",
       "  ('다', 'Eomi'),\n",
       "  'EOS']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_prod[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, which):\n",
    "        self.which = which\n",
    "        self.words = Counter()\n",
    "        self.truncwords = []\n",
    "        if self.which == \"review\":\n",
    "            self.word2idx = {'UNK': 0, 'PAD' : 1, 'SOS' : 2, 'EOS' : 3}\n",
    "            self.idx2word = {0 : 'UNK', 1 : 'PAD', 2 : 'SOS', 3 : 'EOS'}\n",
    "        elif self.which == \"tag\":\n",
    "            self.word2idx = {'UNK' : 0, 'PAD' : 1}\n",
    "            self.idx2word = {0 : 'UNK', 1 : 'PAD'}\n",
    "            \n",
    "    def build_vocab(self, data):\n",
    "        if self.which == \"review\":\n",
    "            for p in data:\n",
    "                tokens =  p[-1]\n",
    "                self.words.update(tokens)\n",
    "        elif self.which == \"tag\":\n",
    "            for p in data:\n",
    "                tokens = p[-2]\n",
    "                self.words.update(tokens)\n",
    "        self.trunc_words = [tok for tok, count in self.words.items()]\n",
    "        \n",
    "    def init_vocab(self):\n",
    "        if self.which == \"review\":\n",
    "            self.word2idx = {'UNK': 0, 'PAD' : 1, 'SOS' : 2, 'EOS' : 3}\n",
    "            self.idx2word = {0 : 'UNK', 1 : 'PAD', 2 : 'SOS', 3 : 'EOS'}\n",
    "        elif self.which == \"tag\":\n",
    "            self.word2idx = {'UNK' : 0, 'PAD' : 1}\n",
    "            self.idx2word = {0 : 'UNK', 1 : 'PAD'}\n",
    "            \n",
    "    def filter_by_freq(self, min_count):\n",
    "        trunc_words = [tok for tok, count in self.words.items() if count >= min_count]\n",
    "        print(len(trunc_words), \"out of\" , len(self.words), \"words left, which is\",\n",
    "              len(trunc_words)/len(self.words)*100.0, \"%\")\n",
    "        self.trunc_words = trunc_words\n",
    "        self.init_vocab()\n",
    "        \n",
    "    def build_idx_mapping(self, min_count = 0):\n",
    "        if min_count > 0:\n",
    "            self.filter_by_freq(min_count)\n",
    "        for t in self.trunc_words:\n",
    "            if t not in self.word2idx:\n",
    "                self.idx2word[len(self.word2idx)] = t\n",
    "                self.word2idx[t] = len(self.word2idx)\n",
    "            else:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagVocab = Vocab(which = 'tag')\n",
    "rvVocab = Vocab(which = 'review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagVocab.build_vocab(all_prod)\n",
    "rvVocab.build_vocab(all_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3158 out of 3465 words left, which is 91.13997113997114 %\n"
     ]
    }
   ],
   "source": [
    "tagVocab.build_idx_mapping(min_count = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3527 out of 37012 words left, which is 9.529341835080514 %\n"
     ]
    }
   ],
   "source": [
    "rvVocab.build_idx_mapping(min_count = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2idx, idx2tag = tagVocab.word2idx, tagVocab.idx2word\n",
    "rv2idx, idx2rv = rvVocab.word2idx, rvVocab.idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Products:\n",
    "    def __init__(self):\n",
    "        # rating \n",
    "        self.rating2idx = {}\n",
    "        # category \n",
    "        self.upcat2idx = {}\n",
    "        self.lowcat2idx = {}\n",
    "    \n",
    "    # Rating\n",
    "    def addRating(self, rating_list):\n",
    "        self.rating2idx = {}\n",
    "        for rate in set(rating_list):\n",
    "            self.rating2idx[rate] = len(self.rating2idx)\n",
    "    \n",
    "    # Category\n",
    "    def addCategory(self, cat_list, which):\n",
    "        if which == 'upper':\n",
    "            self.upcat2idx = {}\n",
    "            for cat in set(cat_list):\n",
    "                self.upcat2idx[cat] = len(self.upcat2idx)\n",
    "        elif which == 'lower':\n",
    "            self.lowcat2idx = {}\n",
    "            for cat in set(cat_list):\n",
    "                self.lowcat2idx[cat] = len(self.lowcat2idx)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 카테고리, 만족도 정보 담은 객체 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper = ['top', 'outer', 'bottom', 'shoes', 'bags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = ['12015003002','12015003003','12015003004',\n",
    "       '12015003005','12015003006','12015003007']\n",
    "outer = ['12015001001', '12015004001', '12015004002', '12015004003', '12015004004']\n",
    "bottom = ['12015009001', '12015009002', '12015009003', '12015009005', '12015009004']\n",
    "shoes = ['12016013001001', '12016013003001', '12016013007001', '12016013001002', '12016013002001',\n",
    "         '12016013004004', '12016013003002', '12016013002002', '12016013004005', '12016013001003',\n",
    "         '12016013004002', '12016013003003', '12016013001004', '12016013005', '12016013004003',\n",
    "         '12016013003004', '12016013001005', '12016013006', '12016013003005', '12016013007003',\n",
    "         '12016013002003', '12016013004001', '12016013008', '12016013009', '12016013001006',\n",
    "         '12016013003006', '12016013001007', '12016013003007', '12016013007004', '12016013007002',\n",
    "         '12016013010', '12016013001008', '12016013001009','12016013004006']\n",
    "bags = ['12016021001', '12016021002', '12016021003', '12016001001',\n",
    "        '12016001004001', '12016001002', '12016001003', '12016001004002',\n",
    "        '12016021004', '12016001004003', '12016001004004', '12016021005',\n",
    "        '12016021006', '12016021007', '12016021008', '12016001004006',\n",
    "        '12016001005', '12016001006', '12016001007', '12016001008', '12016001009']\n",
    "\n",
    "lower = top + outer + bottom + shoes + bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating = ['추천', '적극추천', '만족', '보통', '불만', '추천안함']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = Products()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.addCategory(cat_list = lower, which = 'lower')\n",
    "meta.addCategory(cat_list = upper, which = 'upper')\n",
    "meta.addRating(Rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'만족': 4, '보통': 5, '불만': 3, '적극추천': 2, '추천': 1, '추천안함': 0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.rating2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'12015001001': 53,\n",
       " '12015003002': 43,\n",
       " '12015003003': 42,\n",
       " '12015003004': 7,\n",
       " '12015003005': 70,\n",
       " '12015003006': 65,\n",
       " '12015003007': 63,\n",
       " '12015004001': 22,\n",
       " '12015004002': 47,\n",
       " '12015004003': 55,\n",
       " '12015004004': 40,\n",
       " '12015009001': 15,\n",
       " '12015009002': 10,\n",
       " '12015009003': 60,\n",
       " '12015009004': 14,\n",
       " '12015009005': 11,\n",
       " '12016001001': 18,\n",
       " '12016001002': 35,\n",
       " '12016001003': 49,\n",
       " '12016001004001': 52,\n",
       " '12016001004002': 1,\n",
       " '12016001004003': 2,\n",
       " '12016001004004': 56,\n",
       " '12016001004006': 4,\n",
       " '12016001005': 59,\n",
       " '12016001006': 61,\n",
       " '12016001007': 62,\n",
       " '12016001008': 8,\n",
       " '12016001009': 31,\n",
       " '12016013001001': 0,\n",
       " '12016013001002': 13,\n",
       " '12016013001003': 45,\n",
       " '12016013001004': 26,\n",
       " '12016013001005': 57,\n",
       " '12016013001006': 27,\n",
       " '12016013001007': 33,\n",
       " '12016013001008': 48,\n",
       " '12016013001009': 69,\n",
       " '12016013002001': 50,\n",
       " '12016013002002': 19,\n",
       " '12016013002003': 58,\n",
       " '12016013003001': 23,\n",
       " '12016013003002': 44,\n",
       " '12016013003003': 46,\n",
       " '12016013003004': 36,\n",
       " '12016013003005': 41,\n",
       " '12016013003006': 21,\n",
       " '12016013003007': 30,\n",
       " '12016013004001': 20,\n",
       " '12016013004002': 28,\n",
       " '12016013004003': 34,\n",
       " '12016013004004': 39,\n",
       " '12016013004005': 24,\n",
       " '12016013004006': 17,\n",
       " '12016013005': 38,\n",
       " '12016013006': 32,\n",
       " '12016013007001': 16,\n",
       " '12016013007002': 3,\n",
       " '12016013007003': 67,\n",
       " '12016013007004': 25,\n",
       " '12016013008': 66,\n",
       " '12016013009': 51,\n",
       " '12016013010': 12,\n",
       " '12016021001': 64,\n",
       " '12016021002': 5,\n",
       " '12016021003': 6,\n",
       " '12016021004': 54,\n",
       " '12016021005': 68,\n",
       " '12016021006': 37,\n",
       " '12016021007': 9,\n",
       " '12016021008': 29}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.lowcat2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 벡터로 인코딩! 드디어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_num(review, metadict, vocab_tag, vocab_rv, cat = 'lower'):\n",
    "    # 리뷰의 정보를 분리\n",
    "    rating = review[0]\n",
    "    if cat == 'both':\n",
    "        uppercat = review[1]\n",
    "    lowercat = str(review[2])\n",
    "    tags = review[3]\n",
    "    text = review[4]\n",
    "        \n",
    "    rating_num = torch.tensor([metadict.rating2idx.get(rating)]).type(torch.long)\n",
    "    #cat_num = torch.tensor([metadict.upcat2idx.get(uppercat)]) # upper category\n",
    "    cat_num = torch.tensor([metadict.lowcat2idx.get(lowercat)]).type(torch.long) # lower category\n",
    "    tag_num = torch.tensor([vocab_tag.word2idx.get(t, params['UNK_IDX']) for t in tags]).type(torch.long)\n",
    "    rv_num = torch.tensor([vocab_rv.word2idx.get(w, params['UNK_IDX']) for w in text]).type(torch.long)\n",
    "    \n",
    "    return [rating_num, cat_num, tag_num, rv_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(all_reviews, metadict, vocab_tag, vocab_rv):\n",
    "    \"\"\"\n",
    "    all_reviews : 모든 리뷰에 대한 리스트\n",
    "    p : Product 클라스의 객체 (인코딩할때 참조!)\n",
    "    \"\"\"\n",
    "    encode_prod = [] # 숫자의 리스트\n",
    "    for review in tqdm_notebook(all_reviews): # 일단 열개만 해봅시다\n",
    "        encode_prod.append(review_to_num(review, metadict, vocab_tag, vocab_rv)) \n",
    "    return encode_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "005280fb4bb04be08d920e8b6e923880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=163733), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "encoded_data = prepareData(all_prod, metadict = meta, \n",
    "                           vocab_rv = rvVocab, vocab_tag = tagVocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(batch, which):\n",
    "    if which == 'tag':\n",
    "        idx = 2\n",
    "    elif which == 'review':\n",
    "        idx = 3\n",
    "    max_len = np.max([len(sample[idx]) for sample in batch])\n",
    "    tag_padding = params['PAD_IDX']\n",
    "    #batch\n",
    "    batch_data = tag_padding*np.ones((len(batch), max_len))\n",
    "    for j in range(len(batch)):\n",
    "        cur_len = len(batch[j][idx])\n",
    "        if cur_len > 0:\n",
    "            batch_data[j][:cur_len] = np.array(batch[j][idx])\n",
    "    batch_data = torch.from_numpy(batch_data)\n",
    "    batch_data = torch.tensor(batch_data).type(torch.long)\n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iterator(data, batch_size):\n",
    "    batch = random.sample(data, batch_size)\n",
    "    \n",
    "    rating = torch.cat([sample[0] for sample in batch], dim=-1).view(-1,1)\n",
    "    category = torch.cat([sample[1] for sample in batch], dim=-1).view(-1,1)\n",
    "    \n",
    "    tag = pad(batch = batch, which = 'tag')\n",
    "    review = pad(batch = batch, which = 'review')\n",
    "    \n",
    "    return rating, category, tag, review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, c, t, rv = data_iterator(data = encoded_data, batch_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,  3360,  1335,   521,  2568,   355,  1749,   235,   144,\n",
       "           102,   680,   235,  2315,  1188,   212,   112,    46,    94,\n",
       "            40,    41,  3157,    40,    13,  1430,     3,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    2,   140,   394,  1068,   276,   787,    12,   383,     3,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    2,  2992,   130,   870,  1376,  3000,  1288,   770,    83,\n",
       "          2952,   538,   308,   178,    45,  1192,  3305,    38,    12,\n",
       "            55,    96,  1793,    29,   392,   393,  2992,   130,   869,\n",
       "          1376,   503,   666,   103,   413,    13,  3184,  1614,     7,\n",
       "             8,  3305,  1608,    45,     1,   107,    29,     3],\n",
       "        [    2,  3024,    27,   340,   108,  1085,  3023,    27,  1629,\n",
       "            80,  3103,   348,  1939,   477,    12,   315,   842,   178,\n",
       "           215,   311,    29,     3,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    2,  1946,   224,   229,     3,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hwijeen_3.6]",
   "language": "python",
   "name": "conda-env-hwijeen_3.6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
