{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딕셔너리를 만드는 범용 함수 생성 (-> 리뷰, 태그에 대해 각각의 딕셔너리 만들어야함!)\n",
    "from collections import Counter\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'PAD_WORD' : 'PAD', 'PAD_IDX' : 0, 'UNK_WORD' : 'UNK', 'UNK_IDX' : 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/products.pkl', 'rb') as data:\n",
    "    all_prod = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, which):\n",
    "        self.which = which\n",
    "        self.words = Counter()\n",
    "        self.truncwords = []\n",
    "        if self.which == \"review\":\n",
    "            self.word2idx = {'UNK': 0, 'PAD' : 1, 'SOS' : 2, 'EOS' : 3}\n",
    "            self.idx2word = {0 : 'UNK', 1 : 'PAD', 2 : 'SOS', 3 : 'EOS'}\n",
    "        elif self.which == \"tag\":\n",
    "            self.word2idx = {'UNK' : 0, 'PAD' : 1}\n",
    "            self.idx2word = {0 : 'UNK', 1 : 'PAD'}\n",
    "            \n",
    "    def build_vocab(self, data):\n",
    "        if self.which == \"review\":\n",
    "            for p in data:\n",
    "                tokens =  p[-1]\n",
    "                self.words.update(tokens)\n",
    "        elif self.which == \"tag\":\n",
    "            for p in data:\n",
    "                tokens = p[-2]\n",
    "                self.words.update(tokens)\n",
    "        self.trunc_words = [tok for tok, count in self.words.items()]\n",
    "        \n",
    "    def init_vocab(self):\n",
    "        if self.which == \"review\":\n",
    "            self.word2idx = {'UNK': 0, 'PAD' : 1, 'SOS' : 2, 'EOS' : 3}\n",
    "            self.idx2word = {0 : 'UNK', 1 : 'PAD', 2 : 'SOS', 3 : 'EOS'}\n",
    "        elif self.which == \"tag\":\n",
    "            self.word2idx = {'UNK' : 0, 'PAD' : 1}\n",
    "            self.idx2word = {0 : 'UNK', 1 : 'PAD'}\n",
    "            \n",
    "    def filter_by_freq(self, min_count):\n",
    "        trunc_words = [tok for tok, count in self.words.items() if count >= min_count]\n",
    "        print(len(trunc_words), \"out of\" , len(self.words), \"words left, which is\",\n",
    "              len(trunc_words)/len(self.words)*100.0, \"%\")\n",
    "        self.trunc_words = trunc_words\n",
    "        self.init_vocab()\n",
    "        \n",
    "    def build_idx_mapping(self, min_count = 0):\n",
    "        if min_count > 0:\n",
    "            self.filter_by_freq(min_count)\n",
    "        for t in self.trunc_words:\n",
    "            if t not in self.word2idx:\n",
    "                self.idx2word[len(self.word2idx)] = t\n",
    "                self.word2idx[t] = len(self.word2idx)\n",
    "            else:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagVocab = Vocab(which = 'tag')\n",
    "rvVocab = Vocab(which = 'review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagVocab.build_vocab(all_prod)\n",
    "rvVocab.build_vocab(all_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3158 out of 3465 words left, which is 91.13997113997114 %\n"
     ]
    }
   ],
   "source": [
    "tagVocab.build_idx_mapping(min_count = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rvVocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c98b7e6dcb27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrvVocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_idx_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'rvVocab' is not defined"
     ]
    }
   ],
   "source": [
    "rvVocab.build_idx_mapping(min_count = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2idx, idx2tag = tagVocab.word2idx, tagVocab.idx2word\n",
    "rv2idx, idx2rv = rvVocab.word2idx, rvVocab.idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Products:\n",
    "    def __init__(self):\n",
    "        # rating \n",
    "        self.rating2idx = {}\n",
    "        # category \n",
    "        self.upcat2idx = {}\n",
    "        self.lowcat2idx = {}\n",
    "    \n",
    "    # Rating\n",
    "    def addRating(self, rating_list):\n",
    "        self.rating2idx = {}\n",
    "        for rate in set(rating_list):\n",
    "            self.rating2idx[rate] = len(self.rating2idx)\n",
    "    \n",
    "    # Category\n",
    "    def addCategory(self, cat_list, which):\n",
    "        if which == 'upper':\n",
    "            self.upcat2idx = {}\n",
    "            for cat in set(cat_list):\n",
    "                self.upcat2idx[cat] = len(self.upcat2idx)\n",
    "        elif which == 'lower':\n",
    "            self.lowcat2idx = {}\n",
    "            for cat in set(cat_list):\n",
    "                self.lowcat2idx[cat] = len(self.lowcat2idx)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 카테고리, 만족도 정보 담은 객체 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper = ['top', 'outer', 'bottom', 'shoes', 'bags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = ['12015003002','12015003003','12015003004',\n",
    "       '12015003005','12015003006','12015003007']\n",
    "outer = ['12015001001', '12015004001', '12015004002', '12015004003', '12015004004']\n",
    "bottom = ['12015009001', '12015009002', '12015009003', '12015009005', '12015009004']\n",
    "shoes = ['12016013001001', '12016013003001', '12016013007001', '12016013001002', '12016013002001',\n",
    "         '12016013004004', '12016013003002', '12016013002002', '12016013004005', '12016013001003',\n",
    "         '12016013004002', '12016013003003', '12016013001004', '12016013005', '12016013004003',\n",
    "         '12016013003004', '12016013001005', '12016013006', '12016013003005', '12016013007003',\n",
    "         '12016013002003', '12016013004001', '12016013008', '12016013009', '12016013001006',\n",
    "         '12016013003006', '12016013001007', '12016013003007', '12016013007004', '12016013007002',\n",
    "         '12016013010', '12016013001008', '12016013001009','12016013004006']\n",
    "bags = ['12016021001', '12016021002', '12016021003', '12016001001',\n",
    "        '12016001004001', '12016001002', '12016001003', '12016001004002',\n",
    "        '12016021004', '12016001004003', '12016001004004', '12016021005',\n",
    "        '12016021006', '12016021007', '12016021008', '12016001004006',\n",
    "        '12016001005', '12016001006', '12016001007', '12016001008', '12016001009']\n",
    "\n",
    "lower = top + outer + bottom + shoes + bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating = ['추천', '적극추천', '만족', '보통', '불만', '추천안함']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = Products()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.addCategory(cat_list = lower, which = 'lower')\n",
    "meta.addCategory(cat_list = upper, which = 'upper')\n",
    "meta.addRating(Rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'추천': 0, '적극추천': 1, '불만': 2, '보통': 3, '만족': 4, '추천안함': 5}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.rating2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'12016013008': 0,\n",
       " '12016001007': 1,\n",
       " '12016013003004': 2,\n",
       " '12016013001001': 3,\n",
       " '12016001004002': 4,\n",
       " '12016013001006': 5,\n",
       " '12015003006': 6,\n",
       " '12016013002002': 7,\n",
       " '12016013001004': 8,\n",
       " '12016013009': 9,\n",
       " '12016013007004': 10,\n",
       " '12016013004004': 11,\n",
       " '12016013001002': 12,\n",
       " '12016013003001': 13,\n",
       " '12015004004': 14,\n",
       " '12016001002': 15,\n",
       " '12016013006': 16,\n",
       " '12016013001008': 17,\n",
       " '12016013003002': 18,\n",
       " '12016013004002': 19,\n",
       " '12016013005': 20,\n",
       " '12015003005': 21,\n",
       " '12015009004': 22,\n",
       " '12016001004004': 23,\n",
       " '12016001004003': 24,\n",
       " '12016001005': 25,\n",
       " '12016021002': 26,\n",
       " '12016013001003': 27,\n",
       " '12016021005': 28,\n",
       " '12016013001005': 29,\n",
       " '12016001004006': 30,\n",
       " '12016021008': 31,\n",
       " '12016013004003': 32,\n",
       " '12016013003007': 33,\n",
       " '12016001009': 34,\n",
       " '12015003004': 35,\n",
       " '12016013007001': 36,\n",
       " '12016001006': 37,\n",
       " '12015001001': 38,\n",
       " '12016013007002': 39,\n",
       " '12015004002': 40,\n",
       " '12015009002': 41,\n",
       " '12016013001009': 42,\n",
       " '12015004001': 43,\n",
       " '12015003002': 44,\n",
       " '12015003007': 45,\n",
       " '12016013003003': 46,\n",
       " '12016001004001': 47,\n",
       " '12016013007003': 48,\n",
       " '12016021006': 49,\n",
       " '12016013002001': 50,\n",
       " '12016013002003': 51,\n",
       " '12015003003': 52,\n",
       " '12015009003': 53,\n",
       " '12016013010': 54,\n",
       " '12015009001': 55,\n",
       " '12016013001007': 56,\n",
       " '12016013004006': 57,\n",
       " '12016021003': 58,\n",
       " '12016001003': 59,\n",
       " '12016013003006': 60,\n",
       " '12015009005': 61,\n",
       " '12016013004005': 62,\n",
       " '12015004003': 63,\n",
       " '12016021001': 64,\n",
       " '12016013003005': 65,\n",
       " '12016021007': 66,\n",
       " '12016001001': 67,\n",
       " '12016021004': 68,\n",
       " '12016001008': 69,\n",
       " '12016013004001': 70}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.lowcat2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 벡터로 인코딩! 드디어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['추천',\n",
       " 'bags',\n",
       " 12016021001,\n",
       " ['여자',\n",
       "  '가방',\n",
       "  '쇼핑몰',\n",
       "  '여자',\n",
       "  '옷',\n",
       "  '쇼핑몰',\n",
       "  '추천',\n",
       "  '대여',\n",
       "  '쇼핑몰',\n",
       "  '대여',\n",
       "  '쇼핑몰',\n",
       "  '여자',\n",
       "  '지갑',\n",
       "  '추천',\n",
       "  '여자',\n",
       "  '동전지갑',\n",
       "  '귀여운',\n",
       "  '동전지갑',\n",
       "  '퍼',\n",
       "  '동전지갑',\n",
       "  '여자',\n",
       "  '겨울',\n",
       "  '코디',\n",
       "  '여자',\n",
       "  '지갑',\n",
       "  '쇼핑몰'],\n",
       " ['SOS',\n",
       "  ('귀여운', 'Adjective'),\n",
       "  ('동전지갑', 'Noun'),\n",
       "  ('♡', 'Foreign'),\n",
       "  ('복실복실', 'Adverb'),\n",
       "  ('귀여운', 'Adjective'),\n",
       "  ('털', 'Noun'),\n",
       "  ('동전지갑', 'Noun'),\n",
       "  ('입니', 'Adjective'),\n",
       "  ('다', 'Eomi'),\n",
       "  ('.', 'Punctuation'),\n",
       "  ('가방', 'Noun'),\n",
       "  ('키링', 'Noun'),\n",
       "  ('으로도', 'Josa'),\n",
       "  ('괜찮', 'Adjective'),\n",
       "  ('구요', 'Eomi'),\n",
       "  ('~', 'Punctuation'),\n",
       "  ('열쇠', 'Noun'),\n",
       "  ('동전', 'Noun'),\n",
       "  ('립스틱', 'Noun'),\n",
       "  ('.', 'Punctuation'),\n",
       "  ('등', 'Noun'),\n",
       "  ('작은', 'Adjective'),\n",
       "  ('물건', 'Noun'),\n",
       "  ('들', 'Suffix'),\n",
       "  ('.', 'Punctuation'),\n",
       "  ('넣고', 'Verb'),\n",
       "  ('다니', 'Verb'),\n",
       "  ('기', 'Noun'),\n",
       "  ('에도', 'Josa'),\n",
       "  ('안성맞춤', 'Noun'),\n",
       "  ('입니', 'Adjective'),\n",
       "  ('다', 'Eomi'),\n",
       "  'EOS']]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_prod[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "review = all_prod[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = review[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_num(review, metadict, vocab_tag, vocab_rv, cat = 'lower'):\n",
    "    # 리뷰의 정보를 분리\n",
    "    rating = review[0]\n",
    "    if cat == 'both':\n",
    "        uppercat = review[1]\n",
    "    lowercat = str(review[2])\n",
    "    tags = review[3]\n",
    "    text = review[4]\n",
    "        \n",
    "    rating_num = torch.tensor([metadict.rating2idx.get(rating)]).type(torch.long)\n",
    "    #cat_num = torch.tensor([metadict.upcat2idx.get(uppercat)]) # upper category\n",
    "    cat_num = torch.tensor([metadict.lowcat2idx.get(lowercat)]).type(torch.long) # lower category\n",
    "    tag_num = torch.tensor([vocab_tag.word2idx.get(t, params['UNK_IDX']) for t in tags]).type(torch.long)\n",
    "    rv_num = torch.tensor([vocab_rv.word2idx.get(w, params['UNK_IDX']) for w in text]).type(torch.long)\n",
    "    \n",
    "    return [rating_num, cat_num, tag_num, rv_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(all_reviews, metadict, vocab_tag, vocab_rv):\n",
    "    \"\"\"\n",
    "    all_reviews : 모든 리뷰에 대한 리스트\n",
    "    p : Product 클라스의 객체 (인코딩할때 참조!)\n",
    "    \"\"\"\n",
    "    encode_prod = [] # 숫자의 리스트\n",
    "    for review in tqdm_notebook(all_reviews): # 일단 열개만 해봅시다\n",
    "        encode_prod.append(review_to_num(review, metadict, vocab_tag, vocab_rv)) \n",
    "    return encode_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9365b2fc83614c1d90611e198d6bbff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=184342), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "encoded_data = prepareData(all_prod, metadict = meta, \n",
    "                           vocab_rv = rvVocab, vocab_tag = tagVocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 4]),\n",
       " tensor([ 64]),\n",
       " tensor([  2,   3,   4,   2,   5,   4,   6,   7,   4,   7,   4,   2,\n",
       "           8,   6,   2,   9,  10,   9,  11,   9,   2,  12,  13,   2,\n",
       "           8,   4]),\n",
       " tensor([   2,  156,  157,  158,  117,  159,   88,    3])]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(batch, which):\n",
    "    if which == 'tag':\n",
    "        idx = 2\n",
    "    elif which == 'review':\n",
    "        idx = 3\n",
    "    max_len = np.max([len(sample[idx]) for sample in batch])\n",
    "    tag_padding = params['PAD_IDX']\n",
    "    #batch\n",
    "    batch_data = tag_padding*np.ones((len(batch), max_len))\n",
    "    for j in range(len(batch)):\n",
    "        cur_len = len(batch[j][idx])\n",
    "        if cur_len > 0:\n",
    "            batch_data[j][:cur_len] = np.array(batch[j][idx])\n",
    "    batch_data = torch.LongTensor(batch_data)\n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iterator(data, batch_size):\n",
    "    batch = random.sample(data, batch_size)\n",
    "    \n",
    "    rating = torch.cat([sample[0] for sample in batch], dim=-1).view(-1,1)\n",
    "    category = torch.cat([sample[1] for sample in batch], dim=-1).view(-1,1)\n",
    "    \n",
    "    tag = pad(batch = batch, which = 'tag')\n",
    "    review = pad(batch = batch, which = 'review')\n",
    "    \n",
    "    return rating, category, tag, review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, c, t, rv = data_iterator(data = encoded_data, batch_size = 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
